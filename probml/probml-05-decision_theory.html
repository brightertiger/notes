<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Decision Theory | ML Notes</title>
  <link rel="stylesheet" href="../css/style.css">
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true
      },
      options: { enableMenu: false }
    };
  </script>
</head>
<body>
  <div class="layout">
    
    <aside class="sidebar" id="sidebar">
      <div class="sidebar-header">
        <a href="../index.html" class="sidebar-logo">ML Notes</a>
      </div>
      <nav class="sidebar-nav">
        
        <div class="nav-section eslr">
          <div class="nav-section-title" onclick="this.nextElementSibling.classList.toggle('collapsed')">
            <span class="icon">üìä</span>
            ESLR
          </div>
          <ul class="nav-items collapsed">
            <li class="nav-item"><a href="../eslr/eslr-00.html">ESLR Notes</a></li>
            <li class="nav-item"><a href="../eslr/eslr-01-regression.html">Linear Regression</a></li>
            <li class="nav-item"><a href="../eslr/eslr-02-classification.html">Classification</a></li>
            <li class="nav-item"><a href="../eslr/eslr-03-kernel-methods.html">Kernel Methods</a></li>
            <li class="nav-item"><a href="../eslr/eslr-04-model-assessment.html">Model Assessment and Selection</a></li>
            <li class="nav-item"><a href="../eslr/eslr-08-model-selection.html">Model Inference and Averaging</a></li>
            <li class="nav-item"><a href="../eslr/eslr-09-additive-models.html">Additive Models, Trees, and Related Methods</a></li>
            <li class="nav-item"><a href="../eslr/eslr-10-boosting.html">Boosting and Additive Trees</a></li>
            <li class="nav-item"><a href="../eslr/eslr-15-random-forest.html">Random Forests</a></li>
          </ul>
        </div>
        <div class="nav-section general">
          <div class="nav-section-title" onclick="this.nextElementSibling.classList.toggle('collapsed')">
            <span class="icon">üß†</span>
            General
          </div>
          <ul class="nav-items collapsed">
            <li class="nav-item"><a href="../general/gen-00.html">General ML Notes</a></li>
            <li class="nav-item"><a href="../general/gen-01-basic-statistics.html">Basic Statistics</a></li>
            <li class="nav-item"><a href="../general/gen-02-decision_trees.html">Decision Trees</a></li>
            <li class="nav-item"><a href="../general/gen-03-boosting.html">Boosting</a></li>
            <li class="nav-item"><a href="../general/gen-04-xgboost.html">XGBoost</a></li>
            <li class="nav-item"><a href="../general/gen-05-clustering.html">Clustering</a></li>
            <li class="nav-item"><a href="../general/gen-06-support_vector_machines.html">Support Vector Machines</a></li>
            <li class="nav-item"><a href="../general/gen-07-dimensionality_reduction.html">Dimensionality Reduction</a></li>
            <li class="nav-item"><a href="../general/gen-08-regression.html">Regression</a></li>
          </ul>
        </div>
        <div class="nav-section jurafsky">
          <div class="nav-section-title" onclick="this.nextElementSibling.classList.toggle('collapsed')">
            <span class="icon">üí¨</span>
            Jurafsky
          </div>
          <ul class="nav-items collapsed">
            <li class="nav-item"><a href="../jurafsky/jfsky-00.html">Speech and Language Processing Notes</a></li>
            <li class="nav-item"><a href="../jurafsky/jfsky-01-regex.html">Regular Expressions and Text Processing</a></li>
            <li class="nav-item"><a href="../jurafsky/jfsky-02-tokenization.html">N-Grams and Language Models</a></li>
            <li class="nav-item"><a href="../jurafsky/jfsky-03-vectors.html">Vector Semantics and Word Embeddings</a></li>
            <li class="nav-item"><a href="../jurafsky/jfsky-04-sequence.html">Sequence Architectures: RNNs, LSTMs, and Attention</a></li>
            <li class="nav-item"><a href="../jurafsky/jfsky-05-encoder.html">Encoder-Decoder Models</a></li>
            <li class="nav-item"><a href="../jurafsky/jfsky-06-transfer.html">Transfer Learning and Pre-trained Models</a></li>
          </ul>
        </div>
        <div class="nav-section probml">
          <div class="nav-section-title" onclick="this.nextElementSibling.classList.toggle('collapsed')">
            <span class="icon">üìà</span>
            ProbML
          </div>
          <ul class="nav-items">
            <li class="nav-item"><a href="probml-00.html">Probabilistic Machine Learning Notes</a></li>
            <li class="nav-item"><a href="probml-01-introduction.html">Introduction to Machine Learning</a></li>
            <li class="nav-item"><a href="probml-02-probability.html">Probability Foundations</a></li>
            <li class="nav-item"><a href="probml-03-probability.html">Probability: Advanced Topics</a></li>
            <li class="nav-item"><a href="probml-04-statistics.html">Statistics</a></li>
            <li class="nav-item"><a href="probml-05-decision_theory.html" class="active">Decision Theory</a></li>
            <li class="nav-item"><a href="probml-06-information_theory.html">Information Theory</a></li>
            <li class="nav-item"><a href="probml-08-optimization.html">Optimization</a></li>
            <li class="nav-item"><a href="probml-09-discriminant_analysis.html">Discriminant Analysis</a></li>
            <li class="nav-item"><a href="probml-10-logistic_regression.html">Logistic Regression</a></li>
            <li class="nav-item"><a href="probml-11-linear_regression.html">Linear Regression</a></li>
            <li class="nav-item"><a href="probml-13-ffnn.html">Feed-Forward Neural Networks</a></li>
            <li class="nav-item"><a href="probml-14-cnn.html">Convolutional Neural Networks</a></li>
            <li class="nav-item"><a href="probml-15-rnn.html">Recurrent Neural Networks and Transformers</a></li>
            <li class="nav-item"><a href="probml-16-exemplar.html">Exemplar-Based Methods</a></li>
            <li class="nav-item"><a href="probml-18-trees.html">Decision Trees and Ensembles</a></li>
            <li class="nav-item"><a href="probml-19-ssl.html">Self-Supervised and Semi-Supervised Learning</a></li>
            <li class="nav-item"><a href="probml-21-recsys.html">Recommendation Systems</a></li>
          </ul>
        </div>
      </nav>
    </aside>
    
    <header class="mobile-header">
      <a href="../index.html" class="sidebar-logo">ML Notes</a>
      <button class="mobile-menu-btn" onclick="document.getElementById('sidebar').classList.toggle('open'); document.getElementById('overlay').classList.toggle('visible')">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </header>
    <div class="sidebar-overlay" id="overlay" onclick="document.getElementById('sidebar').classList.remove('open'); this.classList.remove('visible')"></div>
    <main class="main-content">
      <div class="content-wrapper">
        <header class="page-header">
          <div class="breadcrumb">
            <a href="../index.html">Home</a>
            <span>/</span>
            <a href="index.html">ProbML</a>
          </div>
          <h1 class="page-title">Decision Theory</h1>
          <div class="page-meta"><span class="tag">ProbML</span></div>
        </header>
        <article class="content">
          <h1 id="decision-theory">Decision Theory</h1>
<p>Decision theory provides a formal framework for making optimal choices under uncertainty. It bridges the gap between probabilistic predictions and concrete actions.</p>
<h2 id="the-big-picture">The Big Picture</h2>
<p>Having a good model isn&#39;t enough ‚Äî you need to <strong>make decisions</strong>. Decision theory tells us how to choose actions that minimize expected loss (or maximize expected utility).</p>
<p><strong>Key question</strong>: Given uncertainty about the world and different costs for different errors, what should we do?</p>
<hr>
<h2 id="risk-attitudes">Risk Attitudes</h2>
<h3 id="risk-neutrality">Risk Neutrality</h3>
<p>A risk-neutral agent values expected outcomes:</p>
<ul>
<li>$50 for sure = 50% chance of $100</li>
</ul>
<h3 id="risk-aversion">Risk Aversion</h3>
<p>A risk-averse agent prefers certainty:</p>
<ul>
<li>Would take $45 for sure over 50% chance of $100</li>
<li>Most people are risk-averse for gains</li>
</ul>
<h3 id="risk-seeking">Risk Seeking</h3>
<p>A risk-seeking agent prefers uncertainty:</p>
<ul>
<li>Would reject $55 for sure to keep 50% chance of $100</li>
<li>Gamblers exhibit this behavior</li>
</ul>
<hr>
<h2 id="classification-decision-rules">Classification Decision Rules</h2>
<h3 id="zero-one-loss">Zero-One Loss</h3>
<p>The simplest loss: you&#39;re either right or wrong.</p>
<p>$$\ell_{01}(y, \hat{y}) = I{y \neq \hat{y}} = \begin{cases} 0 &amp; \text{if } y = \hat{y} \ 1 &amp; \text{if } y \neq \hat{y} \end{cases}$$</p>
<p><strong>Optimal policy</strong>: Predict the most probable class!</p>
<p>$$\pi^*(x) = \arg\max_c P(Y = c | X = x)$$</p>
<p><strong>Derivation</strong>: The risk (expected loss) for predicting $\hat{y}$:
$$R(\hat{y} | x) = P(Y \neq \hat{y} | x) = 1 - P(Y = \hat{y} | x)$$</p>
<p>Minimizing risk = maximizing the probability of being correct.</p>
<h3 id="cost-sensitive-classification">Cost-Sensitive Classification</h3>
<p>Different errors have different consequences!</p>
<p><strong>Medical diagnosis example</strong>:</p>
<ul>
<li><strong>False Negative</strong> (miss cancer): Potentially fatal</li>
<li><strong>False Positive</strong> (false alarm): Unnecessary tests, anxiety</li>
</ul>
<p>We assign different costs:</p>
<ul>
<li>$\ell_{01}$: Cost of predicting 0 when truth is 1 (false negative)</li>
<li>$\ell_{10}$: Cost of predicting 1 when truth is 0 (false positive)</li>
</ul>
<p><strong>Optimal decision rule</strong>: Predict class 1 if:
$$P(Y=0|x) \cdot \ell_{01} &lt; P(Y=1|x) \cdot \ell_{10}$$</p>
<p><strong>Effect</strong>: Higher cost of false negatives ‚Üí lower threshold for predicting positive.</p>
<h3 id="the-confusion-matrix">The Confusion Matrix</h3>
<p>For binary classification:</p>
<table>
<thead>
<tr>
<th></th>
<th>Predicted Positive</th>
<th>Predicted Negative</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Actually Positive</strong></td>
<td>True Positive (TP)</td>
<td>False Negative (FN)</td>
</tr>
<tr>
<td><strong>Actually Negative</strong></td>
<td>False Positive (FP)</td>
<td>True Negative (TN)</td>
</tr>
</tbody></table>
<p><strong>Key metrics</strong>:</p>
<table>
<thead>
<tr>
<th>Metric</th>
<th>Formula</th>
<th>Meaning</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Sensitivity (Recall, TPR)</strong></td>
<td>TP / (TP + FN)</td>
<td>Of actual positives, how many did we catch?</td>
</tr>
<tr>
<td><strong>Specificity (TNR)</strong></td>
<td>TN / (TN + FP)</td>
<td>Of actual negatives, how many did we correctly identify?</td>
</tr>
<tr>
<td><strong>Precision (PPV)</strong></td>
<td>TP / (TP + FP)</td>
<td>Of predicted positives, how many are correct?</td>
</tr>
<tr>
<td><strong>False Positive Rate (FPR)</strong></td>
<td>FP / (FP + TN)</td>
<td>Of actual negatives, how many did we incorrectly flag?</td>
</tr>
</tbody></table>
<h3 id="the-rejection-option">The Rejection Option</h3>
<p>Sometimes the best decision is to <strong>not decide</strong>.</p>
<p><strong>Setup</strong>:</p>
<ul>
<li>Cost of error: $\lambda_e$</li>
<li>Cost of rejection: $\lambda_r$ (where $\lambda_r &lt; \lambda_e$)</li>
</ul>
<p><strong>Optimal policy</strong>:</p>
<ul>
<li>Predict if confident: $\max_c P(Y=c|x) \geq 1 - \frac{\lambda_r}{\lambda_e}$</li>
<li>Reject (abstain) if uncertain</li>
</ul>
<p><strong>Use case</strong>: Route uncertain cases to human experts.</p>
<hr>
<h2 id="roc-curves">ROC Curves</h2>
<p>The <strong>Receiver Operating Characteristic</strong> curve shows the trade-off between sensitivity and specificity across all classification thresholds.</p>
<h3 id="construction">Construction</h3>
<p>For each threshold œÑ:</p>
<ol>
<li>Compute TPR (sensitivity) and FPR (1 - specificity)</li>
<li>Plot the point (FPR, TPR)</li>
</ol>
<h3 id="interpretation">Interpretation</h3>
<ul>
<li><strong>Perfect classifier</strong>: Goes through (0, 1) ‚Äî 100% TPR, 0% FPR</li>
<li><strong>Random classifier</strong>: Diagonal line from (0, 0) to (1, 1)</li>
<li><strong>Better models</strong>: Curves closer to upper-left corner</li>
</ul>
<h3 id="auc-area-under-the-roc-curve">AUC (Area Under the ROC Curve)</h3>
<p>A single number summarizing performance:</p>
<ul>
<li>AUC = 1.0: Perfect classifier</li>
<li>AUC = 0.5: Random guessing</li>
<li>AUC &gt; 0.7: Generally acceptable</li>
</ul>
<p><strong>Interpretation</strong>: The probability that a randomly chosen positive example ranks higher than a randomly chosen negative example.</p>
<h3 id="equal-error-rate-eer">Equal Error Rate (EER)</h3>
<p>The point where FPR = FNR. Lower is better.</p>
<hr>
<h2 id="precision-recall-curves">Precision-Recall Curves</h2>
<h3 id="when-to-use">When to Use</h3>
<p>ROC curves can be misleading with <strong>class imbalance</strong> (when one class is much more common).</p>
<p><strong>Example</strong>: In fraud detection, 99.9% of transactions are legitimate. A model that predicts &quot;not fraud&quot; always achieves:</p>
<ul>
<li>99.9% accuracy</li>
<li>100% specificity</li>
<li>0% recall (catches no fraud!)</li>
</ul>
<h3 id="pr-curve-construction">PR Curve Construction</h3>
<p>For each threshold:</p>
<ol>
<li>Compute Precision and Recall</li>
<li>Plot the point (Recall, Precision)</li>
</ol>
<h3 id="key-properties">Key Properties</h3>
<ul>
<li>No dependence on TN (unlike ROC)</li>
<li>Sensitive to class imbalance</li>
<li>Baseline is the positive class proportion</li>
</ul>
<h3 id="summary-metrics">Summary Metrics</h3>
<p><strong>Precision @ K</strong>: Precision when retrieving top K results</p>
<p><strong>Average Precision (AP)</strong>: Area under the (interpolated) PR curve</p>
<p><strong>mAP</strong>: Mean AP across multiple queries/classes</p>
<p><strong>F-Score</strong>: Harmonic mean of precision and recall
$$F_\beta = \frac{(1 + \beta^2) \cdot P \cdot R}{\beta^2 P + R}$$</p>
<ul>
<li>F‚ÇÅ: Equal weight to precision and recall</li>
<li>F‚ÇÇ: Weights recall higher</li>
<li>F‚ÇÄ.‚ÇÖ: Weights precision higher</li>
</ul>
<p><strong>Why harmonic mean?</strong> It penalizes if either P or R is very low.</p>
<hr>
<h2 id="regression-losses">Regression Losses</h2>
<h3 id="common-loss-functions">Common Loss Functions</h3>
<table>
<thead>
<tr>
<th>Loss</th>
<th>Formula</th>
<th>Properties</th>
</tr>
</thead>
<tbody><tr>
<td><strong>MSE</strong></td>
<td>$\frac{1}{N}\sum(y - \hat{y})^2$</td>
<td>Sensitive to outliers; corresponds to Gaussian likelihood</td>
</tr>
<tr>
<td><strong>MAE</strong></td>
<td>$\frac{1}{N}\sum|y - \hat{y}|$</td>
<td>Robust to outliers; corresponds to Laplace likelihood</td>
</tr>
<tr>
<td><strong>Huber</strong></td>
<td>MSE for small errors, MAE for large</td>
<td>Best of both worlds</td>
</tr>
</tbody></table>
<h3 id="quantile-loss">Quantile Loss</h3>
<p>For predicting the q-th quantile:
$$L_q(y, \hat{y}) = \begin{cases} q \cdot (y - \hat{y}) &amp; \text{if } y &gt; \hat{y} \ (1-q) \cdot (\hat{y} - y) &amp; \text{if } y \leq \hat{y} \end{cases}$$</p>
<p><strong>Asymmetric penalty</strong>: Different costs for over- vs under-prediction.</p>
<hr>
<h2 id="model-calibration">Model Calibration</h2>
<p>A model is <strong>well-calibrated</strong> if its predicted probabilities match actual frequencies.</p>
<p><strong>Example</strong>: Among all predictions with confidence 80%, about 80% should be correct.</p>
<h3 id="reliability-diagrams">Reliability Diagrams</h3>
<ul>
<li><strong>x-axis</strong>: Predicted probability (binned)</li>
<li><strong>y-axis</strong>: Actual proportion of positives in each bin</li>
<li><strong>Perfect calibration</strong>: Points fall on the diagonal</li>
</ul>
<h3 id="why-calibration-matters">Why Calibration Matters</h3>
<ul>
<li>For decision making, we need accurate probabilities</li>
<li>Many models (especially neural networks) are overconfident</li>
<li>Calibration can be fixed post-hoc (Platt scaling, isotonic regression)</li>
</ul>
<hr>
<h2 id="bayesian-model-selection">Bayesian Model Selection</h2>
<h3 id="the-bayesian-approach">The Bayesian Approach</h3>
<p>Choose the model m that maximizes posterior probability:
$$p(m | D) \propto p(D | m) \cdot p(m)$$</p>
<p><strong>Marginal likelihood</strong> (evidence):
$$p(D | m) = \int p(D | \theta, m) \cdot p(\theta | m) d\theta$$</p>
<p>This integral automatically penalizes complexity (Occam&#39;s Razor).</p>
<h3 id="model-comparison-criteria">Model Comparison Criteria</h3>
<p><strong>AIC (Akaike Information Criterion)</strong>
$$\text{AIC} = -2 \cdot \text{LL} + 2k$$</p>
<p>Where k = number of parameters.</p>
<p><strong>Intuition</strong>: Approximates out-of-sample predictive performance.</p>
<p><strong>BIC (Bayesian Information Criterion)</strong>
$$\text{BIC} = -2 \cdot \text{LL} + k \cdot \log N$$</p>
<p>Where N = number of observations.</p>
<p><strong>Intuition</strong>: Approximates Bayesian model evidence; penalizes complexity more heavily than AIC.</p>
<h3 id="aic-vs-bic">AIC vs BIC</h3>
<table>
<thead>
<tr>
<th>Criterion</th>
<th>Penalty</th>
<th>Selects</th>
<th>Best For</th>
</tr>
</thead>
<tbody><tr>
<td>AIC</td>
<td>2k</td>
<td>Larger models</td>
<td>Prediction</td>
</tr>
<tr>
<td>BIC</td>
<td>k log N</td>
<td>Smaller models</td>
<td>Finding &quot;true&quot; model</td>
</tr>
</tbody></table>
<h3 id="mdl-minimum-description-length">MDL (Minimum Description Length)</h3>
<p>Information-theoretic view:
$$\text{MDL} = L(\text{model}) + L(\text{data}|\text{model})$$</p>
<p>Choose the model that gives the shortest description of the data.</p>
<hr>
<h2 id="frequentist-decision-theory">Frequentist Decision Theory</h2>
<h3 id="risk-of-an-estimator">Risk of an Estimator</h3>
<p>$$R(\theta, \hat{\theta}) = \mathbb{E}_{p(D|\theta)}[L(\theta, \hat{\theta}(D))]$$</p>
<p>The expected loss when the true parameter is Œ∏.</p>
<h3 id="types-of-risk">Types of Risk</h3>
<p><strong>Bayes Risk</strong>: Average over prior on Œ∏
$$R_B = \int R(\theta, \hat{\theta}) p(\theta) d\theta$$</p>
<p><strong>Maximum Risk</strong>: Worst-case over all Œ∏
$$R_{max} = \max_\theta R(\theta, \hat{\theta})$$</p>
<h3 id="empirical-risk-minimization">Empirical Risk Minimization</h3>
<p><strong>Population Risk</strong>: Expected loss on true distribution
$$R(f) = \mathbb{E}_{p^*(x,y)}[\ell(y, f(x))]$$</p>
<p><strong>Empirical Risk</strong>: Average loss on training data
$$\hat{R}(f) = \frac{1}{N}\sum_{i=1}^N \ell(y_i, f(x_i))$$</p>
<p><strong>The gap</strong>: Estimation error = $\hat{R}(f) - R(f)$</p>
<h3 id="structural-risk-minimization">Structural Risk Minimization</h3>
<p>Add complexity penalty to prevent overfitting:
$$\hat{f} = \arg\min_f \left[\hat{R}(f) + \lambda C(f)\right]$$</p>
<hr>
<h2 id="statistical-learning-theory">Statistical Learning Theory</h2>
<h3 id="pac-learning">PAC Learning</h3>
<p>A concept is <strong>Probably Approximately Correct (PAC) learnable</strong> if:</p>
<ul>
<li>With high probability (1 - Œ¥)</li>
<li>We can find a hypothesis with low error (‚â§ Œµ)</li>
<li>Using polynomial time and data</li>
</ul>
<h3 id="vc-dimension">VC Dimension</h3>
<p>Measures the &quot;capacity&quot; or complexity of a hypothesis class.</p>
<p><strong>Definition</strong>: Maximum number of points that can be <strong>shattered</strong> (perfectly classified for any labeling).</p>
<p><strong>Examples</strong>:</p>
<ul>
<li>Linear classifiers in d dimensions: VC = d + 1</li>
<li>A line in 2D: VC = 3</li>
</ul>
<h3 id="generalization-bounds">Generalization Bounds</h3>
<p>VC theory gives bounds like:
$$R(f) \leq \hat{R}(f) + O\left(\sqrt{\frac{\text{VC}}{N}}\right)$$</p>
<p><strong>Implication</strong>: Lower VC dimension ‚Üí better generalization.</p>
<hr>
<h2 id="hypothesis-testing">Hypothesis Testing</h2>
<h3 id="the-setup">The Setup</h3>
<ul>
<li><strong>Null hypothesis</strong> $H_0$: Default assumption (e.g., &quot;no effect&quot;)</li>
<li><strong>Alternative hypothesis</strong> $H_1$: What we want to show</li>
</ul>
<h3 id="error-types">Error Types</h3>
<table>
<thead>
<tr>
<th></th>
<th>H‚ÇÄ True</th>
<th>H‚ÇÅ True</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Reject H‚ÇÄ</strong></td>
<td>Type I Error (Œ±)</td>
<td>Correct</td>
</tr>
<tr>
<td><strong>Accept H‚ÇÄ</strong></td>
<td>Correct</td>
<td>Type II Error (Œ≤)</td>
</tr>
</tbody></table>
<ul>
<li><strong>Significance level</strong> Œ±: P(reject H‚ÇÄ | H‚ÇÄ true)</li>
<li><strong>Power</strong> 1 - Œ≤: P(reject H‚ÇÄ | H‚ÇÅ true)</li>
</ul>
<h3 id="p-value">p-value</h3>
<p>The probability, under the null hypothesis, of observing a test statistic at least as extreme as what was observed.</p>
<p><strong>Common misconception</strong>: p-value is NOT P(H‚ÇÄ is true | data)!</p>
<h3 id="likelihood-ratio-test">Likelihood Ratio Test</h3>
<p>Compare how well each hypothesis explains the data:
$$\Lambda = \frac{p(D | H_0)}{p(D | H_1)}$$</p>
<p><strong>Neyman-Pearson Lemma</strong>: The likelihood ratio test is the most powerful test for a given significance level.</p>
<hr>
<h2 id="summary">Summary</h2>
<table>
<thead>
<tr>
<th>Concept</th>
<th>Key Insight</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Decision Rule</strong></td>
<td>Map probabilities to actions</td>
</tr>
<tr>
<td><strong>Cost-Sensitive</strong></td>
<td>Different errors have different costs</td>
</tr>
<tr>
<td><strong>ROC Curve</strong></td>
<td>Trade-off between TPR and FPR</td>
</tr>
<tr>
<td><strong>PR Curve</strong></td>
<td>Better for imbalanced classes</td>
</tr>
<tr>
<td><strong>Calibration</strong></td>
<td>Predicted probabilities should match reality</td>
</tr>
<tr>
<td><strong>AIC/BIC</strong></td>
<td>Trade-off between fit and complexity</td>
</tr>
<tr>
<td><strong>VC Dimension</strong></td>
<td>Theoretical measure of model complexity</td>
</tr>
<tr>
<td><strong>Hypothesis Testing</strong></td>
<td>Formal framework for statistical evidence</td>
</tr>
</tbody></table>

        </article>
        <nav class="page-navigation">
        <a href="probml-04-statistics.html" class="nav-link prev">
          <span class="nav-link-label">‚Üê Previous</span>
          <span class="nav-link-title">Statistics</span>
        </a>
        <a href="probml-06-information_theory.html" class="nav-link next">
          <span class="nav-link-label">Next ‚Üí</span>
          <span class="nav-link-title">Information Theory</span>
        </a></nav>
      </div>
    </main>
  </div>
  <script>
    document.addEventListener('scroll', function() {
      const btn = document.querySelector('.back-to-top');
      if (btn) btn.classList.toggle('visible', window.scrollY > 300);
    });
  </script>
</body>
</html>