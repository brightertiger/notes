
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Recommendation Systems | My Notes</title>
  <link rel="stylesheet" href="../css/style.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap">
  <!-- MathJax for LaTeX support -->
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true
      },
      options: {
        enableMenu: false
      }
    };
  </script>
</head>
<body>
  <div class="container">
    <header>
      <h1>Recommendation Systems</h1>
      
      <a href="../index.html" class="home-link">‚Üê Back to Home</a>
    </header>
    <main class="content">
      <h1 id="recommendation-systems">Recommendation Systems</h1>
<ul>
<li><p>Feedback Types</p>
<ul>
<li>Explicit<ul>
<li>Ratings, likes, or dislikes provided directly by users</li>
<li>Sparse, values often missing (not missing at random)</li>
<li>Higher quality but harder to collect</li>
</ul>
</li>
<li>Implicit<ul>
<li>Inferred from user behavior - clicks, watches, purchases, etc.</li>
<li>Sparse, positive-only feedback (absence doesn&#39;t mean dislike)</li>
<li>Easier to collect but noisier</li>
</ul>
</li>
</ul>
</li>
<li><p>Collaborative Filtering</p>
<ul>
<li><p>Users collaborate indirectly to help recommend items</p>
</li>
<li><p>User-based: Recommend items that similar users liked</p>
<ul>
<li>$\hat{y}<em>{ui} = \frac{\sum</em>{u&#39;} \text{sim}(u, u&#39;) y_{u&#39;, i}}{\sum_{u&#39;} \text{sim}(u, u&#39;)}$</li>
</ul>
</li>
<li><p>Item-based: Recommend items that are similar to what the user already likes</p>
</li>
<li><p>Similarity calculations typically use common ratings between users/items</p>
</li>
<li><p>Data sparsity makes similarity calculation challenging</p>
</li>
<li><p>Matrix Factorization</p>
<ul>
<li>View the problem as matrix completion</li>
<li>Predict all missing entries in the ratings matrix</li>
<li>Optimization: $L = ||Z - Y||^2$ (for observed entries only)</li>
<li>Break up Z into low-rank matrices: $Z = U^TV$</li>
<li>U represents user embeddings, V represents item embeddings</li>
<li>Can&#39;t use SVD directly due to missing values</li>
<li>Use ALS (Alternating Least Squares): Estimate U given V, then V given U</li>
<li>Add biases to account for user/item rating tendencies:<ul>
<li>$\hat{y}_{ui} = \mu + b_u + c_i + u_u^T v_i$<ul>
<li>$\mu$ is global average rating</li>
<li>$b_u$ is user bias (rating tendency)</li>
<li>$c_i$ is item bias (intrinsic quality)</li>
<li>$u_u^T v_i$ is user-item interaction</li>
</ul>
</li>
<li>$L = \sum_{(u,i) \in \text{observed}} (y_{ui} - \hat{y}_{ui})^2 + \lambda(\sum ||u_u||^2 + \sum ||v_i||^2)$</li>
</ul>
</li>
</ul>
</li>
<li><p>Probabilistic Matrix Factorization</p>
<ul>
<li>Bayesian approach to matrix factorization</li>
<li>$p(Y=y_{ui}) = \mathcal{N}(\mu + b_u + c_i + u_u^T v_i, \sigma^2)$</li>
<li>Can add priors on user/item vectors</li>
</ul>
</li>
</ul>
</li>
<li><p>Bayesian Personalized Ranking (BPR)</p>
<ul>
<li>For implicit feedback data</li>
<li>Ranking approach: Model ranks items user interacted with (positive set) ahead of others (negative set)</li>
<li>$p(y = (u,i,j) | \theta) = \sigma(f(u,i;\theta) - f(u,j;\theta))$<ul>
<li>$f(u,i;\theta)$ is predicted score for user u and item i</li>
</ul>
</li>
<li>Use hinge or logistic loss to estimate parameters</li>
<li>Samples triplets (user, positive item, negative item) for training</li>
</ul>
</li>
<li><p>Factorization Machines (FM)</p>
<ul>
<li>Generalization of matrix factorization that can incorporate side features</li>
<li>Represent user-item pairs as feature vectors:<ul>
<li>$x = \text{concat}[\text{user_features}, \text{item_features}]$</li>
</ul>
</li>
<li>Model:<ul>
<li>$f(x) = \mu + \sum w_i x_i + \sum_{i&lt;j} (v_i \cdot v_j) x_i x_j$</li>
</ul>
</li>
<li>The dot product term captures pairwise interactions between features</li>
<li>Uses low-rank approximation to reduce parameter count</li>
<li>Can easily incorporate context (time, location, etc.) and user/item metadata</li>
<li>Loss functions:<ul>
<li>Explicit feedback: MSE or MAE</li>
<li>Implicit feedback: Ranking loss (BPR)</li>
</ul>
</li>
</ul>
</li>
<li><p>Cold-Start Problem</p>
<ul>
<li>Difficult to generate predictions for new users or items with no history</li>
<li>Solutions:<ul>
<li>Content-based approaches using item/user metadata</li>
<li>Hybrid models combining collaborative and content-based methods</li>
<li>Active learning to efficiently collect initial preferences</li>
<li>Transfer learning from related domains</li>
</ul>
</li>
</ul>
</li>
<li><p>Exploration-Exploitation Tradeoff</p>
<ul>
<li>Counterfactual challenge: Users might like items they never see</li>
<li>Recommendation systems must balance:<ul>
<li>Exploitation: Recommend items likely to be relevant based on history</li>
<li>Exploration: Recommend items with uncertain but potentially high value</li>
</ul>
</li>
<li>Approaches:<ul>
<li>Multi-armed bandits (Thompson Sampling, UCB)</li>
<li>Contextual bandits for personalized exploration</li>
<li>Diversity promotion in recommendations</li>
</ul>
</li>
</ul>
</li>
</ul>

    </main>
    <footer>
      <p>Generated with Markdown Notes Static Site Generator</p>
    </footer>
  </div>
</body>
</html>
  