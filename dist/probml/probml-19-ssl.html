<!DOCTYPE html><html lang="en"><head><link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600&amp;display=swap" rel="stylesheet">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SSL</title>
    <link rel="stylesheet" href="../styles.css">

    <!-- MathJax for equation rendering -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async="" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
    // MathJax configuration
    window.MathJax = {
        tex: {
            inlineMath: [['$', '$']],
            displayMath: [['$$', '$$']]
        },
        svg: {
            fontCache: 'global'
        }
    };
    </script>
    </head>

<body>
    <div class="container">
        <aside class="sidebar">
    <a href="../index.html" class="home-link">
        <svg class="home-icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
            <path d="M3 9l9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"></path>
            <polyline points="9 22 9 12 15 12 15 22"></polyline>
        </svg>
    </a>
    <h2>Navigation</h2>
    <div class="nav-section">
        <h3>Eslr Notes</h3>
        <ul>
            <li><a href="eslr-00.html">Introduction</a></li>
<li><a href="eslr-01-regression.html">01-Regression</a></li>
<li><a href="eslr-02-classification.html">02-Classification</a></li>
<li><a href="eslr-03-kernel-methods.html">03-Kernel-Methods</a></li>
<li><a href="eslr-04-model-assessment.html">04-Model-Assessment</a></li>
<li><a href="eslr-08-model-selection.html">08-Model-Selection</a></li>
<li><a href="eslr-09-additive-models.html">09-Additive-Models</a></li>
<li><a href="eslr-10-boosting.html">10-Boosting</a></li>
<li><a href="eslr-15-random-forest.html">15-Random-Forest</a></li>
        </ul>
    </div><div class="nav-section">
        <h3>General Notes</h3>
        <ul>
            <li><a href="gen-00.html">00</a></li>
<li><a href="gen-01-basic-statistics.html">01-Basic-Statistics</a></li>
<li><a href="gen-02-decision_trees.html">02-Decision Trees</a></li>
<li><a href="gen-03-boosting.html">03-Boosting</a></li>
<li><a href="gen-04-xgboost.html">04-Xgboost</a></li>
<li><a href="gen-05-clustering.html">05-Clustering</a></li>
<li><a href="gen-06-support_vector_machines.html">06-Support Vector Machines</a></li>
<li><a href="gen-07-dimensionality_reduction.html">07-Dimensionality Reduction</a></li>
<li><a href="gen-08-regression.html">08-Regression</a></li>
        </ul>
    </div><div class="nav-section">
        <h3>Jurafsky Notes</h3>
        <ul>
            <li><a href="jfsky-00.html">00</a></li>
<li><a href="jfsky-01-regex.html">01-Regex</a></li>
<li><a href="jfsky-02-tokenization.html">02-Tokenization</a></li>
<li><a href="jfsky-03-vectors.html">03-Vectors</a></li>
<li><a href="jfsky-04-sequence.html">04-Sequence</a></li>
<li><a href="jfsky-05-encoder.html">05-Encoder</a></li>
<li><a href="jfsky-06-transfer.html">06-Transfer</a></li>
        </ul>
    </div><div class="nav-section">
        <h3>Probml Notes</h3>
        <ul>
            <li><a href="probml-00.html">Introduction</a></li>
<li><a href="probml-01-introduction.html">Introduction (Detailed)</a></li>
<li><a href="probml-02-probability.html">02-probability</a></li>
<li><a href="probml-03-probability.html">Probability (Advanced)</a></li>
<li><a href="probml-04-statistics.html">04-statistics</a></li>
<li><a href="probml-05-decision_theory.html">05-decision Theory</a></li>
<li><a href="probml-06-information_theory.html">06-information Theory</a></li>
<li><a href="probml-08-optimization.html">08-optimization</a></li>
<li><a href="probml-09-discriminant_analysis.html">09-discriminant Analysis</a></li>
<li><a href="probml-10-logistic_regression.html">10-logistic Regression</a></li>
<li><a href="probml-11-linear_regression.html">11-linear Regression</a></li>
<li><a href="probml-13-ffnn.html">13-ffnn</a></li>
<li><a href="probml-14-cnn.html">14-cnn</a></li>
<li><a href="probml-15-rnn.html">15-rnn</a></li>
<li><a href="probml-16-exemplar.html">16-exemplar</a></li>
<li><a href="probml-18-trees.html">18-trees</a></li>
        </ul>
    </div></aside>

        <main class="content"><h1>SSL</h1>
<ul>
<li><p>Data Augmentation</p>
<ul>
<li>Artificially modified versions of input vectors that may appear in real world data</li>
<li>Improves accuracy, makes model robust</li>
<li>Empirical risk minimization to vicinical risk minimization</li>
<li>Minimizing risk in the vicinity of input data point</li>
</ul>
</li>
<li><p>Transfer Learning </p>
<ul>
<li>Some data poor tasks may have structural similarity to other data rich tasks </li>
<li>Transferring information from one dataset to another via shared parameters of a model </li>
<li>Pretrain the model on a large source dataset </li>
<li>Fine tune the model on a small target dataset </li>
<li>Chop-off the head of the pretrained model and add a new one </li>
<li>The parameters may be frozen during fine-tuning </li>
<li>In case the parameters aren't frozen, use small learning rates.</li>
</ul>
</li>
<li><p>Adapters </p>
<ul>
<li>Modify the model structure to customize feature extraction </li>
<li>For example: Add MLPs after transformer blocks and initialize them for identity mappings </li>
<li>Much less parameters to be learned during fine-tuning</li>
</ul>
</li>
<li><p>Pre-training</p>
<ul>
<li>Can be supervised or unsupervised.</li>
<li>Supervised<ul>
<li>Imagenet is supervised pretraining.</li>
<li>For unrelated domains, less helpful.</li>
<li>More like speedup trick with a good initialization.</li>
</ul>
</li>
<li>Unsupervised<ul>
<li>Use unlabeled dataset</li>
<li>Minimize reconstruction error</li>
</ul>
</li>
<li>Self-supervised<ul>
<li>Labels are created from ulabeled dataset algorithmically</li>
<li>Cloze Task<ul>
<li>Fill in the blanks</li>
</ul>
</li>
<li>Proxy Tasks<ul>
<li>Create representations</li>
<li>Siamese Neural Networks</li>
<li>Capture relationship between inputs</li>
</ul>
</li>
<li>Contrastive Tasks<ul>
<li>Use data augmentation</li>
<li>Ensure that similar inputs have closer representations</li>
</ul>
</li>
</ul>
</li>
<li>SimCLR<ul>
<li>Simple Contrastive Learning for Visual Representations</li>
<li>Pretraining<ul>
<li>Take an unlabeled image X</li>
<li>Apply data augmentation A and A' and get two views X and X'</li>
<li>Apply encoder to both views</li>
<li>Apply projection head to both encodings</li>
<li>Contrastive Loss function with mini-batch to identify the positive pairs</li>
</ul>
</li>
<li>Pretraining<ul>
<li>Finetune the encoder and a task specific head</li>
<li>The original projection head is discarded</li>
</ul>
</li>
<li>NLP Encoders<ul>
<li>Contrastively trained language models</li>
<li>SimCSE: Simple Contrastive Learning for Sentence Embeddings<ul>
<li>Dropout acts as data augmentation</li>
<li>Cosine Similarity between representations</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Non-Contrastive Learning<ul>
<li>BYOL<ul>
<li>Bootstrap your own latent (BYOL)</li>
<li>Two copies of encoder</li>
<li>Teacher: Online, Student: Target</li>
<li>Teacher is EMA of updates made to student</li>
<li>MSE Loss</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Semi-Supervised Learning</p>
<ul>
<li>Learn from labeled + unlabeled data in tandem</li>
<li>Self-Training<ul>
<li>Train the model on labeled data</li>
<li>Run inference on unlabeled data to get predictions (pseudo-labels, machine generated)</li>
<li>Combine machine generated and human generated labels</li>
<li>Self-training is similar to EM algorithm where pseudo-labels are the E-step</li>
</ul>
</li>
<li>Noise Student Training<ul>
<li>Adds noise to student model to improve generalization</li>
<li>Add noise via dropout, stochastic depth, data augmentation</li>
</ul>
</li>
<li>Consistency Regularization<ul>
<li>Model's prediction shouldn't change much for small changes to the input</li>
<li>Can be implemented by passing augmented versions of same image as loss</li>
</ul>
</li>
<li>Label Propagation<ul>
<li>Graph: Nodes are i/p datapoints and edges denote similarity</li>
<li>Use graph clustering to group related nodes</li>
<li>Class labels are assigned to unlabeled data, based on the cluster distribution</li>
<li>Model Labels: Labels of the data points</li>
<li>Propagate the labels in such a way that there is minimal label disagreement between node and it's neighbours</li>
<li>Label guesses for unlabeled data that can be used for superised learning</li>
<li>Details:<ul>
<li>M labeled points, N unlabeled points</li>
<li>T: (M+N) x (M+N) transition matrix of normalized edge weights</li>
<li>Y: Label matrix for class distribution of (M+N) x C dimension</li>
<li>Use transition matrix to propagate labels Y = TY until convergence</li>
</ul>
</li>
<li>Success depends on calculating similarity between data points</li>
</ul>
</li>
<li>Consistency Regularization<ul>
<li>Small perturbation to input data point should not change the model predicitons</li>
</ul>
</li>
</ul>
</li>
<li><p>Generative Models</p>
<ul>
<li>Natural way of using unlabeled data by learning a model of data generative process.</li>
<li>Variational Autoencoders<ul>
<li>Models joint distribution of data (x) and latent variables (z)</li>
<li>First sample: $z \sim p(z)$ and then sample $x\sim p(x|z)$</li>
<li>Encoder: Approximate the posterior</li>
<li>Decoder: Approximate the likelihood</li>
<li>Maximize evidence lower bound of the data (ELBO) (derived from Jensen's ineuqlity)</li>
<li>Use VAEs to learn representations for downstream tasks</li>
</ul>
</li>
<li>Generative Adversarial Netwworks<ul>
<li>Generator: Maps latent distribution to data space</li>
<li>Discriminator: Distinguish between outputs of generator and true distribution</li>
<li>Modify discriminator to predict class labels and fake rather than just fake</li>
</ul>
</li>
</ul>
</li>
<li><p>Active Learning</p>
<ul>
<li>Identify true predictive mapping by quering as few data points as possible</li>
<li>Query Synthesis: Model asks output for any input</li>
<li>Pool Based: Model selects the data point from a pool of ulabeled data points</li>
<li>Maximum Entropy Sampling<ul>
<li>Uncertainty in predicted label</li>
<li>Fails when examples are ambiguous of mislabeled</li>
</ul>
</li>
<li>Bayesian Active Learning by Disagreement (BALD)<ul>
<li>Select examples where model makes predictions tht are highly diverese</li>
</ul>
</li>
</ul>
</li>
<li><p>Few-Shot Learning</p>
<ul>
<li>Learn to predict from very few labeled example</li>
<li>One-Shot Learning: Learn to predict from single example</li>
<li>Zero-Shot Lerning: Learn to predict without labeled examples</li>
<li>Model has to generalize for unseen labels during traning time</li>
<li>Works by learning a distance metric</li>
</ul>
</li>
<li><p>Weak Supervision</p>
<ul>
<li>Exact label not aviabale for data points</li>
<li>Distribution of labels for each case</li>
<li>Soft labels / label smoothing</li>
</ul>
</li>
</ul>
<h1>Semi-Supervised and Self-Supervised Learning</h1>
<ul>
<li><p>Semi-Supervised Learning (SSL): Leveraging both labeled and unlabeled data</p>
<ul>
<li>Motivation: Labels are expensive, unlabeled data is abundant</li>
<li>Assumption: Underlying data distribution contains useful structure</li>
</ul>
</li>
<li><p>Data Augmentation</p>
<ul>
<li>Creates artificial training examples through transformations</li>
<li>Preserves semantic content while changing surface features</li>
<li>Common augmentations:<ul>
<li>Image domain: rotations, flips, color jitter, cropping</li>
<li>Text domain: synonym replacement, back-translation</li>
<li>Audio domain: pitch shifting, time stretching</li>
</ul>
</li>
<li>Theoretical framework: Vicinical risk minimization<ul>
<li>Minimize risk in local neighborhoods around training examples</li>
<li>Improves robustness and generalization</li>
</ul>
</li>
</ul>
</li>
<li><p>Transfer Learning</p>
<ul>
<li>Leverages knowledge from data-rich domains to improve performance in data-poor domains</li>
<li>Process:<ol>
<li>Pretrain model on large source dataset (e.g., ImageNet, Common Crawl)</li>
<li>Adapt model to target task with smaller dataset</li>
<li>Options for adaptation:<ul>
<li>Feature extraction: Freeze pretrained layers, train only new head</li>
<li>Fine-tuning: Update all or subset of pretrained parameters</li>
</ul>
</li>
</ol>
</li>
<li>Parameter-efficient fine-tuning:<ul>
<li>Adapters: Small bottleneck layers added between frozen transformer blocks</li>
<li>LoRA: Low-rank adaptation of weight matrices</li>
<li>Prompt tuning: Learn soft prompts while keeping model parameters frozen</li>
</ul>
</li>
</ul>
</li>
<li><p>Self-Supervised Learning</p>
<ul>
<li><p>Creates supervisory signals from unlabeled data</p>
</li>
<li><p>Pretext tasks:</p>
<ul>
<li>Reconstruction tasks: Autoencoders, masked language modeling</li>
<li>Context prediction: Predict arrangement of shuffled patches</li>
<li>Contrastive tasks: Learn similar representations for related inputs</li>
</ul>
</li>
<li><p>Contrastive Learning</p>
<ul>
<li><p>Learn representations by comparing similar and dissimilar examples</p>
</li>
<li><p>SimCLR framework:</p>
<ol>
<li>Generate two views of each image via augmentation</li>
<li>Encode both views with shared encoder</li>
<li>Apply projection head to map encodings to space for contrastive loss</li>
<li>Contrastive loss: Maximize similarity between positive pairs (same image)<br>and minimize similarity between negative pairs (different images)</li>
<li>For downstream tasks, discard projection head and fine-tune encoder</li>
</ol>
</li>
<li><p>Key challenges:</p>
<ul>
<li>Hard negative mining: Finding informative negative examples</li>
<li>Batch size dependence: Performance scales with number of negatives</li>
<li>Feature collapse: Trivial solutions that ignore semantic content</li>
</ul>
</li>
</ul>
</li>
<li><p>Non-Contrastive Methods</p>
<ul>
<li><p>BYOL (Bootstrap Your Own Latent):</p>
<ul>
<li>Teacher-student architecture with no negative examples</li>
<li>Student network predicts teacher network outputs</li>
<li>Teacher parameters updated via exponential moving average of student</li>
<li>Avoids collapse through asymmetric architecture and predictor networks</li>
</ul>
</li>
<li><p>Masked Autoencoders:</p>
<ul>
<li>Inspired by BERT's success in NLP</li>
<li>Mask significant portions of input (e.g., 75% of image patches)</li>
<li>Train encoder-decoder to reconstruct original input</li>
<li>For downstream tasks, use only encoder</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Practical Considerations</p>
<ul>
<li>Pretraining often provides:<ul>
<li>Better initialization for optimization</li>
<li>More generalizable features</li>
<li>Sample efficiency: Fewer labeled examples needed</li>
</ul>
</li>
<li>Domain gap between pretraining and target task affects transfer effectiveness</li>
<li>Large pretrained models may contain useful knowledge but require careful adaptation</li>
</ul>
</li>
</ul>
<div class="page-navigation"><span class="nav-arrow prev disabled">
                <svg class="arrow" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                    <line x1="19" y1="12" x2="5" y2="12"></line>
                    <polyline points="12 19 5 12 12 5"></polyline>
                </svg>
                Previous
            </span><span class="nav-arrow next disabled">
                <svg class="arrow" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                    <line x1="5" y1="12" x2="19" y2="12"></line>
                    <polyline points="12 5 19 12 12 19"></polyline>
                </svg>
            </span></div></main>
    </div>

    <script src="../script.js"></script>






</body></html>