<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Boosting | ML Notes</title>
  <link rel="stylesheet" href="../css/style.css">
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true
      },
      options: { enableMenu: false }
    };
  </script>
</head>
<body>
  <div class="layout">
    
    <aside class="sidebar" id="sidebar">
      <div class="sidebar-header">
        <a href="../index.html" class="sidebar-logo">ML Notes</a>
      </div>
      <nav class="sidebar-nav">
        
        <div class="nav-section eslr">
          <div class="nav-section-title" onclick="this.nextElementSibling.classList.toggle('collapsed')">
            <span class="icon">üìä</span>
            ESLR
          </div>
          <ul class="nav-items collapsed">
            <li class="nav-item"><a href="../eslr/eslr-00.html">ESLR Notes</a></li>
            <li class="nav-item"><a href="../eslr/eslr-01-regression.html">Linear Regression</a></li>
            <li class="nav-item"><a href="../eslr/eslr-02-classification.html">Classification</a></li>
            <li class="nav-item"><a href="../eslr/eslr-03-kernel-methods.html">Kernel Methods</a></li>
            <li class="nav-item"><a href="../eslr/eslr-04-model-assessment.html">Model Assessment and Selection</a></li>
            <li class="nav-item"><a href="../eslr/eslr-08-model-selection.html">Model Inference and Averaging</a></li>
            <li class="nav-item"><a href="../eslr/eslr-09-additive-models.html">Additive Models, Trees, and Related Methods</a></li>
            <li class="nav-item"><a href="../eslr/eslr-10-boosting.html">Boosting and Additive Trees</a></li>
            <li class="nav-item"><a href="../eslr/eslr-15-random-forest.html">Random Forests</a></li>
          </ul>
        </div>
        <div class="nav-section general">
          <div class="nav-section-title" onclick="this.nextElementSibling.classList.toggle('collapsed')">
            <span class="icon">üß†</span>
            General
          </div>
          <ul class="nav-items">
            <li class="nav-item"><a href="gen-00.html">General ML Notes</a></li>
            <li class="nav-item"><a href="gen-01-basic-statistics.html">Basic Statistics</a></li>
            <li class="nav-item"><a href="gen-02-decision_trees.html">Decision Trees</a></li>
            <li class="nav-item"><a href="gen-03-boosting.html" class="active">Boosting</a></li>
            <li class="nav-item"><a href="gen-04-xgboost.html">XGBoost</a></li>
            <li class="nav-item"><a href="gen-05-clustering.html">Clustering</a></li>
            <li class="nav-item"><a href="gen-06-support_vector_machines.html">Support Vector Machines</a></li>
            <li class="nav-item"><a href="gen-07-dimensionality_reduction.html">Dimensionality Reduction</a></li>
            <li class="nav-item"><a href="gen-08-regression.html">Regression</a></li>
          </ul>
        </div>
        <div class="nav-section jurafsky">
          <div class="nav-section-title" onclick="this.nextElementSibling.classList.toggle('collapsed')">
            <span class="icon">üí¨</span>
            Jurafsky
          </div>
          <ul class="nav-items collapsed">
            <li class="nav-item"><a href="../jurafsky/jfsky-00.html">Speech and Language Processing Notes</a></li>
            <li class="nav-item"><a href="../jurafsky/jfsky-01-regex.html">Regular Expressions and Text Processing</a></li>
            <li class="nav-item"><a href="../jurafsky/jfsky-02-tokenization.html">N-Grams and Language Models</a></li>
            <li class="nav-item"><a href="../jurafsky/jfsky-03-vectors.html">Vector Semantics and Word Embeddings</a></li>
            <li class="nav-item"><a href="../jurafsky/jfsky-04-sequence.html">Sequence Architectures: RNNs, LSTMs, and Attention</a></li>
            <li class="nav-item"><a href="../jurafsky/jfsky-05-encoder.html">Encoder-Decoder Models</a></li>
            <li class="nav-item"><a href="../jurafsky/jfsky-06-transfer.html">Transfer Learning and Pre-trained Models</a></li>
          </ul>
        </div>
        <div class="nav-section probml">
          <div class="nav-section-title" onclick="this.nextElementSibling.classList.toggle('collapsed')">
            <span class="icon">üìà</span>
            ProbML
          </div>
          <ul class="nav-items collapsed">
            <li class="nav-item"><a href="../probml/probml-00.html">Probabilistic Machine Learning Notes</a></li>
            <li class="nav-item"><a href="../probml/probml-01-introduction.html">Introduction to Machine Learning</a></li>
            <li class="nav-item"><a href="../probml/probml-02-probability.html">Probability Foundations</a></li>
            <li class="nav-item"><a href="../probml/probml-03-probability.html">Probability: Advanced Topics</a></li>
            <li class="nav-item"><a href="../probml/probml-04-statistics.html">Statistics</a></li>
            <li class="nav-item"><a href="../probml/probml-05-decision_theory.html">Decision Theory</a></li>
            <li class="nav-item"><a href="../probml/probml-06-information_theory.html">Information Theory</a></li>
            <li class="nav-item"><a href="../probml/probml-08-optimization.html">Optimization</a></li>
            <li class="nav-item"><a href="../probml/probml-09-discriminant_analysis.html">Discriminant Analysis</a></li>
            <li class="nav-item"><a href="../probml/probml-10-logistic_regression.html">Logistic Regression</a></li>
            <li class="nav-item"><a href="../probml/probml-11-linear_regression.html">Linear Regression</a></li>
            <li class="nav-item"><a href="../probml/probml-13-ffnn.html">Feed-Forward Neural Networks</a></li>
            <li class="nav-item"><a href="../probml/probml-14-cnn.html">Convolutional Neural Networks</a></li>
            <li class="nav-item"><a href="../probml/probml-15-rnn.html">Recurrent Neural Networks and Transformers</a></li>
            <li class="nav-item"><a href="../probml/probml-16-exemplar.html">Exemplar-Based Methods</a></li>
            <li class="nav-item"><a href="../probml/probml-18-trees.html">Decision Trees and Ensembles</a></li>
            <li class="nav-item"><a href="../probml/probml-19-ssl.html">Self-Supervised and Semi-Supervised Learning</a></li>
            <li class="nav-item"><a href="../probml/probml-21-recsys.html">Recommendation Systems</a></li>
          </ul>
        </div>
      </nav>
    </aside>
    
    <header class="mobile-header">
      <a href="../index.html" class="sidebar-logo">ML Notes</a>
      <button class="mobile-menu-btn" onclick="document.getElementById('sidebar').classList.toggle('open'); document.getElementById('overlay').classList.toggle('visible')">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </header>
    <div class="sidebar-overlay" id="overlay" onclick="document.getElementById('sidebar').classList.remove('open'); this.classList.remove('visible')"></div>
    <main class="main-content">
      <div class="content-wrapper">
        <header class="page-header">
          <div class="breadcrumb">
            <a href="../index.html">Home</a>
            <span>/</span>
            <a href="index.html">General</a>
          </div>
          <h1 class="page-title">Boosting</h1>
          <div class="page-meta"><span class="tag">General</span></div>
        </header>
        <article class="content">
          <h1 id="boosting">Boosting</h1>
<p>Boosting is one of the most powerful ideas in machine learning: take many &quot;weak&quot; models that are only slightly better than random guessing, and combine them into a &quot;strong&quot; model that achieves high accuracy. It&#39;s like combining many rough rules of thumb into a sophisticated decision-making system.</p>
<h2 id="overview">Overview</h2>
<p><strong>The Key Insight</strong>: Ensemble methods combine multiple models for better predictions.</p>
<p><strong>Two Main Ensemble Paradigms</strong>:</p>
<ul>
<li><strong>Bagging</strong>: Build models in parallel on different data subsets, then average<ul>
<li>Reduces variance (covered in Decision Trees notes)</li>
</ul>
</li>
<li><strong>Boosting</strong>: Build models sequentially, each one focusing on previous mistakes<ul>
<li>Reduces bias</li>
</ul>
</li>
</ul>
<p><strong>Boosting Formulation</strong>:</p>
<ul>
<li>$F(x_i) = \sum_m \alpha_m f_m(x_i)$</li>
<li>$f_m$ = the $m$-th weak learner (typically a small tree)</li>
<li>$\alpha_m$ = weight given to that learner</li>
<li>Each $f_m$ and $\alpha_m$ are fit jointly, considering what came before</li>
</ul>
<p><strong>PAC Learning Framework</strong>:</p>
<ul>
<li>PAC = Probably Approximately Correct</li>
<li>Question: Is a problem &quot;learnable&quot;?</li>
<li>A model is PAC-learnable if we can achieve error &lt; $\epsilon$ with probability &gt; $(1-\delta)$</li>
<li><strong>Strong learner</strong>: Achieves low error with high probability (but complex, needs lots of data)</li>
<li><strong>Weak learner</strong>: Only slightly better than random guessing</li>
</ul>
<p><strong>Schapire&#39;s Breakthrough</strong> (1990): &quot;The Strength of Weak Learnability&quot;</p>
<ul>
<li>Key theorem: If a problem can be solved by a strong learner, it can be solved by combining weak learners</li>
<li>Original mechanism (three hypotheses):<ul>
<li>H1: Train on complete data</li>
<li>H2: Train on a balanced sample of H1&#39;s correct and incorrect predictions</li>
<li>H3: Train on examples where H1 and H2 disagree</li>
<li>Final: Majority vote of H1, H2, H3</li>
</ul>
</li>
<li>Improved performance but couldn&#39;t scale easily ‚Üí led to AdaBoost</li>
</ul>
<p><strong>AdaBoost</strong> (Adaptive Boosting):</p>
<ul>
<li>Construct many hypotheses (not just three)</li>
<li>Key innovation: Sample weights &quot;adapt&quot; based on performance</li>
<li>Correctly classified: weight decreases (pay less attention)</li>
<li>Incorrectly classified: weight increases (focus on mistakes)</li>
</ul>
<p><strong>Weight Update Mechanism</strong>:</p>
<ul>
<li>Learner weight: $\alpha_m = \frac{1}{2}\log\left[\frac{1-\epsilon_m}{\epsilon_m}\right]$</li>
<li>Where $\epsilon_m$ = weighted classification error</li>
<li>Sample weights: <ul>
<li>Correctly classified: $w_i \leftarrow w_i \times e^{-\alpha}$</li>
<li>Incorrectly classified: $w_i \leftarrow w_i \times e^{\alpha}$</li>
</ul>
</li>
</ul>
<p><strong>Common Pitfalls</strong>:</p>
<ul>
<li><strong>Underfitting</strong>: Not enough weak learners in the ensemble</li>
<li><strong>Overfitting</strong>: Using learners that are too complex (not &quot;weak&quot; enough)</li>
</ul>
<h2 id="gradient-boosting">Gradient Boosting</h2>
<p>Gradient Boosting generalizes boosting to any differentiable loss function.</p>
<p><strong>The Key Idea</strong>: Instead of reweighting samples, fit each new learner to the <em>negative gradient</em> of the loss function. The gradient tells us how to &quot;fix&quot; the current predictions.</p>
<p><strong>Why Gradients?</strong>:</p>
<ul>
<li>Gradients point in the direction of steepest increase in loss</li>
<li>Negative gradient = direction to decrease loss most rapidly</li>
<li>The gradient for each point is a proxy for &quot;how poorly is this point being predicted?&quot;</li>
</ul>
<p><strong>Connection to Gradient Descent</strong>:</p>
<ul>
<li>Regular gradient descent: Update <em>parameters</em> in the negative gradient direction</li>
<li>Gradient boosting: Add a <em>new function</em> that approximates the negative gradient</li>
<li>Think of it as gradient descent in &quot;function space&quot;</li>
</ul>
<p><strong>Mathematical Derivation</strong>:</p>
<p>We want to minimize loss by adding a new function $f_m$:</p>
<ul>
<li>Current: $F(x_i) = \sum_{k=1}^{m-1} \alpha_k f_k(x_i)$</li>
<li>Goal: Find $f_m$ to minimize $L(F(x_i) + \alpha f_m(x_i))$</li>
</ul>
<p><strong>Taylor Approximation</strong> (first-order):</p>
<ul>
<li>$L(F + \alpha f_m) \approx L(F) + \alpha f_m \cdot \frac{\partial L}{\partial F}$</li>
<li>The first term is constant; we minimize the second term</li>
<li>We want: $\min \sum_i \frac{\partial L}{\partial F(x_i)} \times \alpha f(x_i)$</li>
</ul>
<p><strong>Pseudo-Residuals</strong>:</p>
<ul>
<li>Define: $r_i = -\frac{\partial L}{\partial F(x_i)}$ (the negative gradient)</li>
<li>Goal becomes: $\min -\sum_i r_i \times \alpha f(x_i)$</li>
<li>The ensemble improves as long as $\sum_i r_i f(x_i) &gt; 0$</li>
</ul>
<p><strong>Why &quot;Pseudo-Residuals&quot;?</strong>:</p>
<ul>
<li>For squared loss: $L = \frac{1}{2}(y - F)^2$</li>
<li>Gradient: $\frac{\partial L}{\partial F} = -(y - F)$</li>
<li>So $r_i = y_i - F(x_i)$ = actual residual!</li>
<li>For other losses, $r_i$ is <em>like</em> a residual (hence &quot;pseudo&quot;)</li>
</ul>
<p><strong>Adapting for CART</strong>:</p>
<ul>
<li>Decision trees minimize squared error naturally</li>
<li>Transform the objective:<ul>
<li>$\min \sum r_i^2 - 2\sum_i r_i \times \alpha f(x_i) + \sum (\alpha f(x_i))^2$</li>
<li>$\min \sum (r_i - \alpha f(x_i))^2$</li>
</ul>
</li>
<li>Now the tree can simply minimize squared error between predictions and pseudo-residuals!</li>
</ul>
<p><strong>Optimal Step Size</strong> (Line Search):</p>
<ul>
<li>$\alpha^* = \frac{\sum r_i f(x_i)}{\sum f(x_i)^2} \approx 1$</li>
</ul>
<p><strong>The Gradient Boosting Algorithm</strong>:</p>
<ol>
<li><p><strong>Initialize</strong> with a constant value: $F_0(x) = \arg\min_\gamma \sum L(y_i, \gamma)$</p>
<ul>
<li>For squared loss: just the mean of $y$</li>
</ul>
</li>
<li><p><strong>For</strong> $m = 1$ to $M$:
 a. Compute pseudo-residuals: $r_{im} = -\frac{\partial L(y_i, F(x_i))}{\partial F(x_i)}$
 b. Fit a tree to $(x_i, r_{im})$
 c. For each leaf $j$, compute optimal output: $\gamma_{jm} = \arg\min_\gamma \sum_{x_i \in R_j} L(y_i, F_m(x_i) + \gamma)$
 d. Update: $F_{m+1}(x) = F_m(x) + \nu \sum_j \gamma_{jm} I(x \in R_j)$</p>
</li>
</ol>
<p><strong>The Shrinkage Parameter</strong> ($\nu$):</p>
<ul>
<li>Also called learning rate</li>
<li>Prevents overfitting by taking small steps</li>
<li>Required because Taylor approximation only works for small changes</li>
<li>Typical values: 0.01 to 0.3</li>
</ul>
<h2 id="extension-to-classification">Extension to Classification</h2>
<p>For classification, we predict log-odds and minimize negative log-likelihood.</p>
<p><strong>Log-Odds to Probability</strong>:</p>
<ul>
<li>$p = \frac{e^{\log(\text{odds})}}{1 + e^{\log(\text{odds})}} = \frac{1}{1 + e^{-\log(\text{odds})}}$</li>
</ul>
<p><strong>The Loss Function</strong> (Negative Log-Likelihood):</p>
<ul>
<li>$\text{NLL} = -\sum [y_i \log(p_i) + (1-y_i)\log(1-p_i)]$</li>
<li>Rewriting in terms of log-odds:</li>
<li>$\text{NLL} = -\sum [y_i \cdot \text{log-odds} - \log(1 + e^{\text{log-odds}})]$</li>
</ul>
<p><strong>Computing Pseudo-Residuals</strong>:</p>
<ul>
<li>$\frac{\partial \text{NLL}}{\partial \log(\text{odds})} = p_i - y_i$</li>
<li>So $r_{im} = y_i - p_i$ (intuitive: how far off is our probability estimate?)</li>
</ul>
<p><strong>Finding Optimal Leaf Values</strong>:</p>
<ul>
<li>For log-loss, minimizing within each leaf isn&#39;t straightforward</li>
<li>Use second-order Taylor approximation:</li>
<li>$\gamma^* = \frac{\sum(y_i - p_i)}{\sum p_i(1-p_i)}$</li>
<li>Numerator: sum of residuals (first derivative)</li>
<li>Denominator: sum of $p(1-p)$ (second derivative, the Hessian)</li>
</ul>
<p><strong>The Classification Algorithm</strong>:</p>
<ol>
<li><p><strong>Initialize</strong>: Log-odds that minimizes NLL (e.g., $\log(\frac{\bar{y}}{1-\bar{y}})$)</p>
</li>
<li><p><strong>For</strong> $m = 1$ to $M$:
 a. Compute residuals: $r_{im} = y_i - p_i$
 b. Fit a tree to $(x_i, r_{im})$
 c. For each leaf $j$: $\gamma_{jm} = \frac{\sum_{i \in R_j}(y_i - p_i)}{\sum_{i \in R_j} p_i(1-p_i)}$
 d. Update: $F_{m+1}(x) = F_m(x) + \nu \sum_j \gamma_{jm} I(x \in R_j)$</p>
</li>
<li><p><strong>Predict</strong>: Convert final log-odds to probability</p>
</li>
</ol>
<h2 id="gradient-boosting-vs-adaboost">Gradient Boosting vs AdaBoost</h2>
<table>
<thead>
<tr>
<th>Aspect</th>
<th>AdaBoost</th>
<th>Gradient Boosting</th>
</tr>
</thead>
<tbody><tr>
<td>Focus</td>
<td>Reweighting misclassified samples</td>
<td>Fitting negative gradient of loss</td>
</tr>
<tr>
<td>Loss function</td>
<td>Exponential loss</td>
<td>Any differentiable loss</td>
</tr>
<tr>
<td>Sample weights</td>
<td>Explicitly updated</td>
<td>Implicitly through gradients</td>
</tr>
<tr>
<td>Optimization</td>
<td>Coordinate descent</td>
<td>Gradient descent in function space</td>
</tr>
</tbody></table>
<p><strong>Key insight</strong>: AdaBoost is a special case of Gradient Boosting with exponential loss!</p>
<h2 id="common-loss-functions">Common Loss Functions</h2>
<p><strong>For Regression</strong>:</p>
<ul>
<li><strong>L2 (Squared Error)</strong>: $L(y, F) = \frac{1}{2}(y - F)^2$<ul>
<li>Gradient = $y - F$ (the actual residual)</li>
<li>Sensitive to outliers</li>
</ul>
</li>
<li><strong>L1 (Absolute Error)</strong>: $L(y, F) = |y - F|$<ul>
<li>Gradient = $\text{sign}(y - F)$</li>
<li>More robust to outliers</li>
</ul>
</li>
<li><strong>Huber Loss</strong>: Combines L1 and L2<ul>
<li>Behaves like L2 for small errors, L1 for large errors</li>
<li>Best of both worlds</li>
</ul>
</li>
</ul>
<p><strong>For Classification</strong>:</p>
<ul>
<li><strong>Log Loss</strong>: $L(y, F) = -y\log(p) - (1-y)\log(1-p)$<ul>
<li>Standard for probability estimation</li>
</ul>
</li>
<li><strong>Exponential Loss</strong>: $L(y, F) = e^{-yF}$<ul>
<li>What AdaBoost minimizes</li>
<li>Very sensitive to outliers</li>
</ul>
</li>
</ul>
<h2 id="regularization-in-gradient-boosting">Regularization in Gradient Boosting</h2>
<p><strong>Learning Rate/Shrinkage</strong> ($\nu$):</p>
<ul>
<li>Scales contribution of each tree</li>
<li>Smaller $\nu$ ‚Üí need more trees, but better generalization</li>
<li>Trade-off: Training time vs. accuracy</li>
</ul>
<p><strong>Subsampling</strong> (Stochastic Gradient Boosting):</p>
<ul>
<li>Use only a fraction of data for each tree (e.g., 50-80%)</li>
<li>Similar to mini-batch gradient descent</li>
<li>Reduces overfitting and training time</li>
</ul>
<p><strong>Early Stopping</strong>:</p>
<ul>
<li>Monitor validation performance</li>
<li>Stop adding trees when validation error stops improving</li>
<li>Prevents overfitting without explicit regularization</li>
</ul>
<p><strong>Tree Constraints</strong>:</p>
<ul>
<li>Maximum depth (typically 3-8 for boosting)</li>
<li>Minimum samples per leaf</li>
<li>Maximum leaf nodes</li>
<li>Shallow trees = weak learners = less overfitting</li>
</ul>
<h2 id="adaboost-for-classification">AdaBoost for Classification</h2>
<p>Let&#39;s derive AdaBoost from scratch to understand its mechanics.</p>
<p><strong>Setup</strong>:</p>
<ul>
<li>Binary classification: $y \in {-1, +1}$</li>
<li>Exponential loss: $L(y_i, f(x_i)) = e^{-y_i f(x_i)}$</li>
<li>This is an upper bound on 0-1 loss</li>
</ul>
<p><strong>Why Exponential Loss?</strong>:</p>
<ul>
<li>If correct prediction: $y_i f(x_i) &gt; 0$ ‚Üí small loss</li>
<li>If wrong prediction: $y_i f(x_i) &lt; 0$ ‚Üí exponentially large loss</li>
<li>Forces the algorithm to focus hard on mistakes</li>
</ul>
<p><strong>Objective Function</strong>:</p>
<ul>
<li>Ensemble: $F(x) = \sum_m \alpha_m f_m(x)$</li>
<li>Loss: $L = \sum_i e^{-y_i F(x_i)}$</li>
</ul>
<p><strong>At Round $m$</strong>:</p>
<ul>
<li>$L = \sum_i e^{-y_i \sum_{k=1}^m \alpha_k f_k(x)}$</li>
<li>$L = \sum_i e^{-y_i \sum_{k=1}^{m-1} \alpha_k f_k(x)} \cdot e^{-y_i \alpha_m f_m(x)}$</li>
<li>Let $w_i^m = e^{-y_i F_{m-1}(x_i)}$ (weights from previous rounds)</li>
<li>$L = \sum_i w_i^m \cdot e^{-y_i \alpha_m f_m(x_i)}$</li>
</ul>
<p><strong>Finding Optimal $\alpha_m$</strong>:</p>
<ul>
<li>Split into correct and incorrect predictions:</li>
<li>$L = \sum_{\text{correct}} w_i e^{-\alpha_m} + \sum_{\text{incorrect}} w_i e^{\alpha_m}$</li>
<li>Let $\epsilon_m$ = weighted misclassification rate</li>
<li>$L = (1-\epsilon_m)e^{-\alpha_m} + \epsilon_m e^{\alpha_m}$</li>
<li>Taking derivative and setting to zero:</li>
<li>$\alpha_m^* = \frac{1}{2}\log\left[\frac{1-\epsilon_m}{\epsilon_m}\right]$</li>
</ul>
<p><strong>Interpreting $\alpha_m$</strong>:</p>
<ul>
<li>If $\epsilon_m = 0$ (perfect): $\alpha_m \to \infty$ (trust this learner completely)</li>
<li>If $\epsilon_m = 0.5$ (random): $\alpha_m = 0$ (ignore this learner)</li>
<li>If $\epsilon_m &gt; 0.5$ (worse than random): $\alpha_m &lt; 0$ (flip predictions)</li>
</ul>
<p><strong>The AdaBoost Algorithm</strong>:</p>
<ol>
<li><p><strong>Initialize</strong>: $w_i = 1/N$ for all samples</p>
</li>
<li><p><strong>For</strong> $m = 1$ to $M$:
 a. Fit weak learner $f_m$ minimizing weighted error
 b. Compute weighted error: $\epsilon_m = \frac{\sum_i w_i I(y_i \neq f_m(x_i))}{\sum_i w_i}$
 c. Compute learner weight: $\alpha_m = \frac{1}{2}\log\left[\frac{1-\epsilon_m}{\epsilon_m}\right]$
 d. Update sample weights: $w_i \leftarrow w_i \cdot e^{\alpha_m I(y_i \neq f_m(x_i))}$
 e. Normalize weights to sum to 1</p>
</li>
<li><p><strong>Final prediction</strong>: $\text{sign}\left(\sum_m \alpha_m f_m(x)\right)$</p>
</li>
</ol>
<p><strong>LogitBoost</strong>: Similar to AdaBoost but minimizes logistic loss</p>
<ul>
<li>$\log(1 + e^{-y_i f(x_i)})$</li>
<li>More robust to noise and outliers than exponential loss</li>
</ul>
<h2 id="notes">Notes</h2>
<p><strong>Why Boosting Works</strong>:</p>
<ul>
<li>Weak learners have high bias, low variance</li>
<li>Boosting gradually reduces bias by focusing on mistakes</li>
<li>Each iteration adds a small amount of complexity</li>
</ul>
<p><strong>Historical Development</strong>:</p>
<ol>
<li>AdaBoost (1995) - Freund &amp; Schapire</li>
<li>AdaBoost interpreted as gradient descent (1999) - Friedman et al.</li>
<li>Generalized to any gradient descent (Gradient Boosting)</li>
</ol>
<p><strong>Gradient Descent vs Gradient Boosting</strong>:</p>
<table>
<thead>
<tr>
<th>Gradient Descent</th>
<th>Gradient Boosting</th>
</tr>
</thead>
<tbody><tr>
<td>Updates model <em>parameters</em></td>
<td>Updates model <em>predictions</em></td>
</tr>
<tr>
<td>Parameters: $\theta \leftarrow \theta - \eta \nabla L$</td>
<td>Predictions: $F \leftarrow F + \nu f_m$</td>
</tr>
<tr>
<td>Fixed model structure</td>
<td>Adds new functions</td>
</tr>
</tbody></table>
<p><strong>Gradient Boosting is a Meta-Model</strong>:</p>
<ul>
<li>It&#39;s not a single model but a <em>framework</em> for combining weak learners</li>
<li>The weak learner can be any model (trees are most common)</li>
<li>The loss function can be customized for different tasks</li>
</ul>

        </article>
        <nav class="page-navigation">
        <a href="gen-02-decision_trees.html" class="nav-link prev">
          <span class="nav-link-label">‚Üê Previous</span>
          <span class="nav-link-title">Decision Trees</span>
        </a>
        <a href="gen-04-xgboost.html" class="nav-link next">
          <span class="nav-link-label">Next ‚Üí</span>
          <span class="nav-link-title">XGBoost</span>
        </a></nav>
      </div>
    </main>
  </div>
  <script>
    document.addEventListener('scroll', function() {
      const btn = document.querySelector('.back-to-top');
      if (btn) btn.classList.toggle('visible', window.scrollY > 300);
    });
  </script>
</body>
</html>