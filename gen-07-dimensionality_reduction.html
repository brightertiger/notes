<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>DS/ML Notes - 7&nbsp; Dimensionality Reduction</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<link href="./gen-08-regression.html" rel="next">
<link href="./gen-06-support_vector_machines.html" rel="prev">
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Dimensionality Reduction</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">DS/ML Notes</a> 
    </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./gen-00.html" class="sidebar-item-text sidebar-link">General ML Notes</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./gen-01-basic-statistics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Basic Statistics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./gen-02-decision_trees.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Decision Trees</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./gen-03-boosting.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Boosting</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./gen-04-xgboost.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">XGBoost</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./gen-05-clustering.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./gen-06-support_vector_machines.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Support Vector Machines</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./gen-07-dimensionality_reduction.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Dimensionality Reduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./gen-08-regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Regression</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./probml-00.html" class="sidebar-item-text sidebar-link">ProbML Notes</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probml-01-introduction.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probml-02-probability.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Probability</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probml-03-probability.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Probability</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probml-04-statistics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Statistics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probml-05-decision_theory.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Decision Theory</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probml-06-information_theory.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Information Theory</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probml-08-optimization.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Optimization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probml-09-discriminant_analysis.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Discriminant Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probml-10-logistic_regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Logistic Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probml-11-linear_regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Linear Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probml-13-ffnn.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Feed Forward NN</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probml-14-cnn.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Convolution NN</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probml-15-rnn.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Recurrent NN</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probml-16-exemplar.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Exemplar Methods</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probml-18-trees.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Trees</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probml-19-ssl.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">SSL</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probml-21-recsys.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Rec Sys</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./eslr-00.html" class="sidebar-item-text sidebar-link">ESLR Notes</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eslr-01-regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eslr-02-classification.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eslr-03-kernel-methods.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Kernel Methods</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eslr-04-model-assessment.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Model Selection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eslr-08-model-selection.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Model Selection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eslr-09-additive-models.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Additive Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eslr-10-boosting.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Boosting</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eslr-15-random-forest.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Random Forests</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./jfsky-00.html" class="sidebar-item-text sidebar-link">SLP Notes</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./jfsky-01-regex.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Regex</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./jfsky-02-tokenization.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Tokenization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./jfsky-03-vectors.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Vectors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./jfsky-04-sequence.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Sequence Architectures</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./jfsky-05-encoder.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Encoder-Decoder Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./jfsky-06-transfer.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Transfer Learning</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#background" id="toc-background" class="nav-link active" data-scroll-target="#background"><span class="toc-section-number">7.1</span>  Background</a></li>
  <li><a href="#principal-component-analysis" id="toc-principal-component-analysis" class="nav-link" data-scroll-target="#principal-component-analysis"><span class="toc-section-number">7.2</span>  Principal Component Analysis</a></li>
  <li><a href="#stochastic-neighbour-embedding-sne" id="toc-stochastic-neighbour-embedding-sne" class="nav-link" data-scroll-target="#stochastic-neighbour-embedding-sne"><span class="toc-section-number">7.3</span>  Stochastic Neighbour Embedding (SNE)</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Dimensionality Reduction</span></h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<section id="background" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="background"><span class="header-section-number">7.1</span> Background</h2>
<ul>
<li>Curse of Dimensionality
<ul>
<li>Data has too many features (n &lt;&lt; p)</li>
<li>Data volume required for good generalization grows exponentially</li>
<li>Same edge (say 10) square and cube
<ul>
<li>1x1 patch covers 1% area in quare</li>
<li>1x1x1 patch covers 0.1% volume in cube</li>
</ul></li>
</ul></li>
<li>Two approaches
<ul>
<li>Feature Selection
<ul>
<li>Use only a subset of original features<br>
</li>
</ul></li>
<li>Latent Features
<ul>
<li>Recombine the original features for more efficient representation</li>
<li>Can be linear or non-linear</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="principal-component-analysis" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="principal-component-analysis"><span class="header-section-number">7.2</span> Principal Component Analysis</h2>
<ul>
<li>Find a linear and orthogonal projection of data from high dimension to low dimension
<ul>
<li>Encode original data <span class="math inline">\(x \in R^D\)</span> using <span class="math inline">\(W \in R^{D \times L}\)</span>
<ul>
<li>Encode: <span class="math inline">\(z = W^T x \in R^L\)</span></li>
</ul></li>
<li>Decode <span class="math inline">\(z\)</span> by projecting it from lower dimension to higher dimension
<ul>
<li>Decode: <span class="math inline">\(\hat x = W z\)</span></li>
</ul></li>
</ul></li>
<li>Objective is to minimize reconstruction error
<ul>
<li><span class="math inline">\(L(w) = {1 \over N} \sum ||x - \hat x||^2\)</span></li>
</ul></li>
<li>Proof: Project all the data to one dimension
<ul>
<li><span class="math inline">\(w_1 \in R^D\)</span></li>
<li><span class="math inline">\(\hat x = z_{1} w_1\)</span></li>
<li>Optimal value of z and w that minimizes reconstruction error</li>
<li><span class="math inline">\(L = {1 \over N} \sum ||x_i - z_{i1} w_1||^2\)</span></li>
<li><span class="math inline">\(L = {1 \over N} \sum (x_i - z_{i1} w_1)^T(x_i - z_{i1} w_1)\)</span></li>
<li><span class="math inline">\(L = {1 \over N} \sum x_i^T x_i -2 z_{i1} w_1^T x_i - z_{i1} w_1^Tw_1 z_{i1}\)</span></li>
<li>Orthonormal Assumption <span class="math inline">\(\implies w_1^Tw_1 = 1\)</span></li>
<li><span class="math inline">\(L = {1 \over N} \sum x_i^T x_i -2 z_{i1} w_1^T x_i - z_{i1}^2\)</span></li>
<li>Take Derivaties wrt z and w</li>
<li><span class="math inline">\({\delta L \over \delta z_{i1}} = {1 \over N} (-2 w_1^T x_i + 2 z_{i1}) = 0\)</span></li>
<li>Optimal Embedding: <span class="math inline">\(z_{i1} = w_1^T x\)</span></li>
<li>Plugging the value of z in L</li>
<li><span class="math inline">\(L = {1 \over N} \sum x_i^T x_i - z_{i1}^2\)</span></li>
<li><span class="math inline">\(L = C - {1 \over N} \sum z_{i1}^2\)</span></li>
<li><span class="math inline">\(L = C - {1 \over N} \sum w_1^T x_i^T x_i w_1\)</span></li>
<li><span class="math inline">\(L = - {1 \over N} w_1^T \Sigma w_1\)</span></li>
<li><span class="math inline">\(\Sigma\)</span> is the Var-Cov matrix of X</li>
<li>The loss can be minimized trivially by scaling <span class="math inline">\(w\)</span></li>
<li>To avoid this, impose a unit-norm constraint on <span class="math inline">\(w\)</span></li>
<li><span class="math inline">\(L = {1 \over N} w_1^T \Sigma w_1 + \lambda (w_1^T w_1 - 1)\)</span></li>
<li><span class="math inline">\({\delta L \over \delta w_1} = -2 \Sigma w_1 + 2 \lambda w_1 = 0\)</span></li>
<li>Optimal w is given by eigen vector of <span class="math inline">\(\Sigma\)</span></li>
<li>To minimize the loss, pick the vector corresponding to highest eigenvalue</li>
</ul></li>
<li>PCA finds vectors that maximize the variance of projected data
<ul>
<li><span class="math inline">\(L = C - {1 \over N} \sum z_{i1}^2\)</span></li>
<li>The original data is scaled</li>
<li><span class="math inline">\(E(z_1) = E(w_1^T x) = 0\)</span></li>
<li><span class="math inline">\(L = C + \text{Var}(z_1)\)</span></li>
</ul></li>
<li>Geometric Explanation
<ul>
<li>Find a new axis to capture the data</li>
<li>Distance of the point from origin is fixed <span class="math inline">\(R^2\)</span></li>
<li><span class="math inline">\(D^2\)</span> if the distance of the point from origin along the new axis (Variance)</li>
<li><span class="math inline">\(\epsilon\)</span> if the vertical distance of the point from the new axis (Distortion)</li>
<li>By Pythagoras theorem <span class="math inline">\(R^2 = D^2 + \epsilon\)</span></li>
<li>PCA maximizes the variance <span class="math inline">\(D^2\)</span></li>
<li>Is equivalent to minimizing distortion <span class="math inline">\(\epsilon\)</span> as <span class="math inline">\(R^2\)</span> is constant</li>
</ul></li>
<li>Eigenvalues euqal the sum-sq(distances) on points on the principal component axis</li>
<li>Use eigenvalues to understand how much variation is captured by each principal component</li>
<li>Use scree plot (varation captured vs # components) to understand how many components should be included</li>
<li>The maximum number of components are equal to the number of features in the original data
<ul>
<li>Full basis</li>
<li>If data is 2D, the eigen value for the 3rd PC will be 0</li>
</ul></li>
<li>Principal components are linear combinations of original features
<ul>
<li>The weights used for linear combinations are called factor loadings</li>
<li>Factor loadings denote the importance of features in capturing variance</li>
</ul></li>
<li>PCA + linear regression is still interpretable
<ul>
<li>Use estimated coefficients and factor loadings to understand how the original variables are being used</li>
</ul></li>
<li>PCA is calculated using SVD (singular value decomposition)
<ul>
<li><span class="math inline">\(X = U S V^T \in R^{N \times D}\)</span>
<ul>
<li><span class="math inline">\(U \in R^{N \times N}\)</span> is orthonormal</li>
<li><span class="math inline">\(S \in R^{N \times D}\)</span> is diagonal</li>
<li><span class="math inline">\(V \in R^{D \times D}\)</span> is orthonormal</li>
</ul></li>
<li><span class="math inline">\(X^T X = (U S V^{T})^T(U S V^{T}) = V(S^TS)V^T\)</span></li>
<li>Since S is a diagonal matrix, <span class="math inline">\(S^TS\)</span> is diagonal as well</li>
<li><span class="math inline">\(X^T X = VDV^T\)</span></li>
<li>On mutiplying both Sides by V: <span class="math inline">\((X^T X)V = VD\)</span></li>
<li>D matrix gives the eigen values and V matrix gives the corresponding eigenvectors</li>
</ul></li>
<li>Notes
<ul>
<li>PCA doesn’t work well if the interrelationships are non-linear
<ul>
<li>Kernel PCA, Factor Analysis</li>
</ul></li>
<li>PCA doesn’t work well in case of outliers</li>
<li>PCA can’t handle missing data</li>
<li>PCA is unsupervised
<ul>
<li>LDA is a supervised dimensionality reduction technique</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="stochastic-neighbour-embedding-sne" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="stochastic-neighbour-embedding-sne"><span class="header-section-number">7.3</span> Stochastic Neighbour Embedding (SNE)</h2>
<ul>
<li>Unsupervised Non-parametric Mehtod for dimensionality reduction</li>
<li>Manifold is a topological space which is locally Euclidean
<ul>
<li>Eath is a 2D surface embedded in a 3D space</li>
<li>High-dimensional data can lie in a low dimenison manifold</li>
</ul></li>
<li>Idea is to preserve nearest neighbours instead of preserving distances</li>
<li>Convert the distances in high-dimension to probabilities
<ul>
<li>Probability the point i will select j as it’s neighbour</li>
<li>Gaussian Kernel</li>
<li><span class="math inline">\(p_{j|i} \propto \exp({|| x_i - x_j||^2 \over 2\sigma_i^2})\)</span></li>
<li><span class="math inline">\(\sigma_i^2\)</span> is the variance for data point i
<ul>
<li>Magnify the scale of points in dense region</li>
<li>Diminish the scale of points in sparse regions</li>
<li>Perplexity parameter (say 30)</li>
<li>Variance will be adjusted to cover approx 30 neighbours</li>
<li>Balance between local and global aspects of the data</li>
</ul></li>
</ul></li>
<li>Initialize the low-dimnesion representations and calculate the same probability
<ul>
<li><span class="math inline">\(q_{j|i} \propto \exp({|| z_i - z_j||^2})\)</span></li>
<li>Variance is assumed to be constant here</li>
</ul></li>
<li>A good representation will preserve the neighbours</li>
<li><span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span> are probability distributions. KL Divergence will capture the distance between them</li>
<li><span class="math inline">\(L = KL(p||q) = \sum_i\sum_j p_{i|j}\log({p_{i|j} \over q_{i|j}})\)</span>
<ul>
<li>If p is high and q is low, the penalty is high</li>
<li>Points were neighbours in high dimension but not in lo dimension</li>
<li>If p is low and q is high, the penalty is low</li>
<li>Unrelated points are pushed closer now</li>
</ul></li>
<li>Calculate <span class="math inline">\(z\)</span> by minimizing KL-Div using SGD
<ul>
<li><span class="math inline">\(\Delta_{z_i} L = 0\)</span></li>
<li><span class="math inline">\(2 \sum (z_i - z_j) (p_{i|j} - q_{i|j} + p_{j|i} - q_{j|i})\)</span></li>
</ul></li>
<li>Symmetric SNE
<ul>
<li>In the above formulation the distances are not symmetric</li>
<li><span class="math inline">\(p_{i|j} \ne p_{j|i}\)</span></li>
<li>To enforce this: <span class="math inline">\(p_{ij} = (p_{i|j} + p_{j|i}) / 2\)</span></li>
<li>Equivalent to using constant variance in high-dimensional space</li>
<li><span class="math inline">\(\Delta_{z_i} L = 4 \sum (z_i - z_j) (p_{ij} - q_{ij})\)</span>
<ul>
<li>Similar to Potential energy in a spring (F = kx)</li>
<li><span class="math inline">\((p_{ij} - q_{ij})\)</span> is k</li>
<li><span class="math inline">\((z_i - z_j)\)</span> is x</li>
</ul></li>
</ul></li>
<li>t-SNE
<ul>
<li>SNE has a crowding problem</li>
<li>Gaussian Kernel pushes moderately far away points in high dimension close together in low dimension (squared errors)</li>
<li>Replace it with t-distribution that has fatter tails (probability goes to 0 slowly)
<ul>
<li>The fatter tails allow dissimilar points to be far apart in lower dimension as well</li>
<li>Removes unwanted attractive forces between points that are modelrately far in high dimension</li>
</ul></li>
<li><span class="math inline">\(q_{j|i} \propto (1+{|| z_i - z_j||^2})^{-1}\)</span></li>
<li><span class="math inline">\(\Delta_{z_i} L = \sum (z_i - z_j) (p_{ij} - q_{ij}) (1 + || z_i - z_j||^2)^{-1}\)</span></li>
<li><span class="math inline">\((1 + || z_i - z_j||^2)^{-1}\)</span> ensures well separated clusters with tightly packed points inside</li>
<li>Introduces strong repulsions between the dissimilar datapoints that are modeled by small pairwise distance in the low-dimensional map</li>
<li>Coordinates after embedding have no inherent meaning</li>
</ul></li>
<li>UMAP
<ul>
<li>Uniform Manifold Approximation and Projection<br>
</li>
<li>Similar to t-SNE but much faster
<ul>
<li>t-SNE calculates all pairwise distances</li>
<li>UMAP calculates distances between close neighbours only</li>
</ul></li>
<li>t-SNE start with random initialization, UMAP start with spectral embeddings</li>
<li>t-SNE moves every points slightly in each iteration, UMAP can move single points or subset of points in each iteration</li>
<li>Mathematics
<ul>
<li>t-SNE uses Gaussian desnity function to calculate the distance between points in high dimension</li>
<li>UMAP uses similarity scores
<ul>
<li>Hyperparameter: number of neighbours (similar to perplexity in t-SNE)</li>
<li>Calculate log(number of neighbours)</li>
<li>Calculate similarity scores</li>
<li><span class="math inline">\(\exp(-(\text{raw distance} - \text{distance to nearest neighbour}) / \sigma\)</span></li>
<li>Rescale the curve such that sum of distances = log(number of neighbours)</li>
</ul></li>
<li>UMAP makes the scores symmetrical by <span class="math inline">\((S_1 + S_2) - S_1S_2\)</span></li>
<li>Initialize a low dimension graph using Spectral Embedding
<ul>
<li>Decompoistion of Graph Laplacian</li>
<li>Graph Laplacian = Degree Matrix - Adjacency Matrix</li>
</ul></li>
<li>Calculate the similarity in low dimension using t-distrbution
<ul>
<li><span class="math inline">\((1 + \alpha d^{2\beta})^{-1}\)</span></li>
<li>The parameters help user control the shape of the curve</li>
</ul></li>
<li>Cost Function
<ul>
<li>Cross-Entropy between graphs</li>
<li><span class="math inline">\(\log(1 - S_{\text{not neighbour}}) - log(S_{\text{neighbour}})\)</span><br>
</li>
</ul></li>
</ul></li>
<li>UMAP can accomodate new data (predict function) without recomputation</li>
</ul></li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./gen-06-support_vector_machines.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Support Vector Machines</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./gen-08-regression.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Regression</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>